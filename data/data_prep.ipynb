{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading dataset and splitting into train, val and test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First import the requiered libraries, and then set the column width to be wider so that the DataFrame is displayed more clearly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import DatasetDict, Dataset, load_dataset\n",
    "\n",
    "pd.set_option('display.max_colwidth', 500)\n",
    "#To reset this option, uncomment the line below and re-run the cell\n",
    "#pd.reset_option('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then it's time to load the dataset for preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load dataset from Hugging Face\n",
    "dataset = load_dataset(\"smartcat/Amazon_Sample_Metadata_2023\", name=\"product2query_V1\", split=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert dataset into Pandas DataFrame for easier processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert dataset to pandas DataFrame\n",
    "df = pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, set the column 'parent_asin' to be the first in line, as it's the product id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_column_order = [\"parent_asin\"] + [col for col in df.columns if col != \"parent_asin\"] \n",
    "df = df[new_column_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>main_category</th>\n",
       "      <th>title</th>\n",
       "      <th>features</th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "      <th>store</th>\n",
       "      <th>brand</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>short_query</th>\n",
       "      <th>long_query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B0C1ND3FVR</td>\n",
       "      <td>All Beauty</td>\n",
       "      <td>Murray &amp; Lanman Florida Water Plastic Bottle 7.5 oz</td>\n",
       "      <td>Unisex\\nNot tested on animals</td>\n",
       "      <td>The enduring popularity of world-famous Florida Water is due to its wonderful light floral scent with lemon overtones. Unchanged since 1808, this revitalizing scent is used as an invigorating splash, aftershave, or fragrant addition to the bath. For more than 200 years men and women have loved the Florida Water scent, named for the Fountain of Youth.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Murray &amp; Lanman</td>\n",
       "      <td>Murray &amp; Lanman</td>\n",
       "      <td>Atlas Ethnic</td>\n",
       "      <td>Florida Water Fragrance</td>\n",
       "      <td>Murray &amp; Lanman Florida Water 7.5 oz Plastic Bottle with Classic Floral Scent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B001PIVFU0</td>\n",
       "      <td>All Beauty</td>\n",
       "      <td>GiGi Professional Multi-Purpose Wax Warmer, with See-Through Cover, White</td>\n",
       "      <td>Thermostat-controlled heating</td>\n",
       "      <td>GiGi Professional Multi-Purpose Wax Warmer with See-Through Cover</td>\n",
       "      <td>25.87</td>\n",
       "      <td>GiGi</td>\n",
       "      <td>GiGi</td>\n",
       "      <td>Barg Engine</td>\n",
       "      <td>GiGi Wax Warmer</td>\n",
       "      <td>GiGi Professional Multi-Purpose Wax Warmer with See-Through Cover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B004ZWH3XG</td>\n",
       "      <td>All Beauty</td>\n",
       "      <td>Garnier Fructis Color Sealer, Instant, Lightweight Leave-In, Color Shield, For Color-Treated Hair, 6 oz.</td>\n",
       "      <td>Seals In Color And Conditions For Extra Softness\\nInfused With Acai Berry And Grape Seed Oil\\nFor Color Treated Hair\\nLightweight Formula</td>\n",
       "      <td>Proven to stop dry-out. Fight fade-out. The lightweight formula, infused with acai berry and grape seed oil, instantly seals in color for longer-lasting vibrancy while improving manageability and delivering lasting softness. Uva and uvb protectant help protect hair. Garnier fructis color shield instant color sealer lightweight leave-in instantly seals in color and conditions for extra softness.</td>\n",
       "      <td>24.00</td>\n",
       "      <td>Garnier</td>\n",
       "      <td>Garnier LLC</td>\n",
       "      <td>Garnier LLC</td>\n",
       "      <td>Garnier Fructis Color Sealer</td>\n",
       "      <td>Garnier Fructis Color Shield Instant Color Sealer for Color-Treated Hair</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  parent_asin main_category  \\\n",
       "0  B0C1ND3FVR    All Beauty   \n",
       "1  B001PIVFU0    All Beauty   \n",
       "2  B004ZWH3XG    All Beauty   \n",
       "\n",
       "                                                                                                      title  \\\n",
       "0                                                       Murray & Lanman Florida Water Plastic Bottle 7.5 oz   \n",
       "1                                 GiGi Professional Multi-Purpose Wax Warmer, with See-Through Cover, White   \n",
       "2  Garnier Fructis Color Sealer, Instant, Lightweight Leave-In, Color Shield, For Color-Treated Hair, 6 oz.   \n",
       "\n",
       "                                                                                                                                    features  \\\n",
       "0                                                                                                              Unisex\\nNot tested on animals   \n",
       "1                                                                                                              Thermostat-controlled heating   \n",
       "2  Seals In Color And Conditions For Extra Softness\\nInfused With Acai Berry And Grape Seed Oil\\nFor Color Treated Hair\\nLightweight Formula   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                     description  \\\n",
       "0                                               The enduring popularity of world-famous Florida Water is due to its wonderful light floral scent with lemon overtones. Unchanged since 1808, this revitalizing scent is used as an invigorating splash, aftershave, or fragrant addition to the bath. For more than 200 years men and women have loved the Florida Water scent, named for the Fountain of Youth.   \n",
       "1                                                                                                                                                                                                                                                                                                                                              GiGi Professional Multi-Purpose Wax Warmer with See-Through Cover   \n",
       "2  Proven to stop dry-out. Fight fade-out. The lightweight formula, infused with acai berry and grape seed oil, instantly seals in color for longer-lasting vibrancy while improving manageability and delivering lasting softness. Uva and uvb protectant help protect hair. Garnier fructis color shield instant color sealer lightweight leave-in instantly seals in color and conditions for extra softness.   \n",
       "\n",
       "   price            store            brand  manufacturer  \\\n",
       "0    NaN  Murray & Lanman  Murray & Lanman  Atlas Ethnic   \n",
       "1  25.87             GiGi             GiGi   Barg Engine   \n",
       "2  24.00          Garnier      Garnier LLC   Garnier LLC   \n",
       "\n",
       "                    short_query  \\\n",
       "0       Florida Water Fragrance   \n",
       "1               GiGi Wax Warmer   \n",
       "2  Garnier Fructis Color Sealer   \n",
       "\n",
       "                                                                      long_query  \n",
       "0  Murray & Lanman Florida Water 7.5 oz Plastic Bottle with Classic Floral Scent  \n",
       "1              GiGi Professional Multi-Purpose Wax Warmer with See-Through Cover  \n",
       "2       Garnier Fructis Color Shield Instant Color Sealer for Color-Treated Hair  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some helper functions to check missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_na(df):\n",
    "    \"\"\"_summary_\n",
    "    Prints sum of NA by columns in DataFrame.\n",
    "\n",
    "    Args:\n",
    "       - df (DataFrame): the DataFrame chunk\n",
    "\n",
    "    Prints:\n",
    "       - Number of NA values by column.\n",
    "    \"\"\"\n",
    "    NANs = df.isnull().sum()\n",
    "    print(\"--------------------\")\n",
    "    print(\"Nulls in dataset:\\n\", NANs)\n",
    "\n",
    "def check_empty_lists(df):\n",
    "    \"\"\"\n",
    "    Prints sum of empty lists by columns in DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        - df (DataFrame): the DataFrame chunk\n",
    "\n",
    "    Prints:\n",
    "        - Number of empty lists by column.\n",
    "    \"\"\"\n",
    "    empty_list_counts = df.apply(lambda col: col.apply(lambda x: x == []).sum())\n",
    "    print(\"--------------------\")\n",
    "    print(\"Empty lists:\")\n",
    "\n",
    "    print(empty_list_counts)\n",
    "\n",
    "\n",
    "def check_empty_strings(df):\n",
    "    \"\"\"\n",
    "    Prints sum of empty strings by columns in DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        - df (DataFrame): the DataFrame chunk\n",
    "\n",
    "    Prints:\n",
    "        - Number of empty strings by column.\n",
    "    \"\"\"\n",
    "    empty_strings = (df == \"\").sum()\n",
    "    print(\"--------------------\")\n",
    "    print(\"Empty strings:\")\n",
    "    print(empty_strings[empty_strings > 0])\n",
    "\n",
    "\n",
    "def check_empty_dictionaries(df):\n",
    "    \"\"\"\n",
    "    Prints the count of empty dictionaries by column in the DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        - df (pd.DataFrame): The DataFrame to check for empty dictionaries.\n",
    "\n",
    "    Prints:\n",
    "        - Number of empty dictionaries by columns.\n",
    "    \"\"\"\n",
    "    empty_dicts = df.apply(\n",
    "        lambda x: x.apply(lambda y: isinstance(y, dict) and len(y) == 0).sum()\n",
    "    )\n",
    "\n",
    "    print(\"--------------------\")\n",
    "    print(\"Empty dictionaries:\")\n",
    "    print(empty_dicts[empty_dicts > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Nulls in dataset:\n",
      " parent_asin           0\n",
      "main_category         0\n",
      "title                 0\n",
      "features              0\n",
      "description           0\n",
      "price            143604\n",
      "store                 0\n",
      "brand             62970\n",
      "manufacturer      62970\n",
      "short_query           0\n",
      "long_query            0\n",
      "dtype: int64\n",
      "--------------------\n",
      "Empty lists:\n",
      "parent_asin      0\n",
      "main_category    0\n",
      "title            0\n",
      "features         0\n",
      "description      0\n",
      "price            0\n",
      "store            0\n",
      "brand            0\n",
      "manufacturer     0\n",
      "short_query      0\n",
      "long_query       0\n",
      "dtype: int64\n",
      "--------------------\n",
      "Empty dictionaries:\n",
      "Series([], dtype: int64)\n",
      "--------------------\n",
      "Empty strings:\n",
      "main_category    14537\n",
      "title               22\n",
      "features         10974\n",
      "store              659\n",
      "short_query        482\n",
      "long_query         482\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "check_na(df)\n",
    "check_empty_lists(df)\n",
    "check_empty_dictionaries(df)\n",
    "check_empty_strings(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to to focus on products that have a Title, and every row that doesn't have it will be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_empty_title = df[df[\"title\"] == '']\n",
    "df_empty_title[\"parent_asin\"]\n",
    "\n",
    "df = df[~df[\"parent_asin\"].isin(df_empty_title[\"parent_asin\"].to_list())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same goes for 'short_query' because it will be our label for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_short_query = df[df[\"short_query\"] == '']\n",
    "df_short_query[\"parent_asin\"]\n",
    "\n",
    "df = df[~df[\"parent_asin\"].isin(df_short_query[\"parent_asin\"].to_list())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Empty strings:\n",
      "main_category    14504\n",
      "features         10956\n",
      "store              659\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "check_empty_strings(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empty categories are set to 'Unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['main_category'] == '', 'main_category'] = 'Unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Empty strings:\n",
      "features    10956\n",
      "store         659\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "check_empty_strings(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyzing ordinal columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_ordinal_columns(df, process_columns=None, skip_columns=None):\n",
    "    \"\"\"\n",
    "    Analyzes specified columns in the DataFrame for unique values and occurrences.\n",
    "\n",
    "    Parameters:\n",
    "        - df (pd.DataFrame): The DataFrame to analyze.\n",
    "        - process_columns (list): List of column names to process. If None, all columns except skip_columns will be processed.\n",
    "        - skip_columns (list): List of column names to skip.\n",
    "\n",
    "    Prints:\n",
    "        - Number of unique values in each processed column.\n",
    "        - Unique values in each processed column.\n",
    "        - Number of occurrences for each unique value in each processed column.\n",
    "    \"\"\"\n",
    "    if skip_columns is None:\n",
    "        skip_columns = []\n",
    "    if process_columns is None:\n",
    "        process_columns = df.columns.tolist()\n",
    "\n",
    "    # Process the specified columns\n",
    "    for column in process_columns:\n",
    "        if column in skip_columns:\n",
    "            continue  # Skip the column if it is in the skip list\n",
    "        print(\"--------------------\")\n",
    "        print(f\"Analyzing column: '{column}'\")\n",
    "        print(\"--------------------\")\n",
    "        # Number of unique values\n",
    "        num_unique = df[column].nunique()\n",
    "        unique_values = df[column].unique()\n",
    "\n",
    "        print(f\"  Number of unique values: {num_unique}\")\n",
    "        print(\"--------------------\")\n",
    "        print(f\"  Unique values: {unique_values}\")\n",
    "        # Count occurrences of each unique value\n",
    "        value_counts = df[column].value_counts()\n",
    "        print(\"--------------------\")\n",
    "        for value, count in value_counts.items():\n",
    "            print(f\"  Number of occurrences of '{value}': {count}\")\n",
    "\n",
    "        print()  # Newline for readability between columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Analyzing column: 'main_category'\n",
      "--------------------\n",
      "  Number of unique values: 36\n",
      "--------------------\n",
      "  Unique values: ['All Beauty' 'Industrial & Scientific' 'Health & Personal Care' 'Baby'\n",
      " 'AMAZON FASHION' 'Amazon Home' 'Arts, Crafts & Sewing'\n",
      " 'Tools & Home Improvement' 'Unknown' 'Office Products'\n",
      " 'Sports & Outdoors' 'Automotive' 'Grocery' 'All Electronics'\n",
      " 'Car Electronics' 'Camera & Photo' 'Pet Supplies' 'Toys & Games'\n",
      " 'Digital Music' 'Handmade' 'Cell Phones & Accessories' 'Computers'\n",
      " 'Musical Instruments' 'Premium Beauty' 'Appliances' 'Movies & TV'\n",
      " 'Amazon Devices' 'Books' 'Video Games' 'Home Audio & Theater'\n",
      " 'Collectible Coins' 'Portable Audio & Accessories' 'GPS & Navigation'\n",
      " 'Sports Collectibles' 'Collectibles & Fine Art' 'Amazon Fire TV']\n",
      "--------------------\n",
      "  Number of occurrences of 'AMAZON FASHION': 168511\n",
      "  Number of occurrences of 'All Beauty': 36412\n",
      "  Number of occurrences of 'Sports & Outdoors': 22845\n",
      "  Number of occurrences of 'Unknown': 14504\n",
      "  Number of occurrences of 'Health & Personal Care': 5218\n",
      "  Number of occurrences of 'Amazon Home': 3369\n",
      "  Number of occurrences of 'Tools & Home Improvement': 1882\n",
      "  Number of occurrences of 'Automotive': 972\n",
      "  Number of occurrences of 'Industrial & Scientific': 644\n",
      "  Number of occurrences of 'Office Products': 482\n",
      "  Number of occurrences of 'Arts, Crafts & Sewing': 336\n",
      "  Number of occurrences of 'Pet Supplies': 332\n",
      "  Number of occurrences of 'Toys & Games': 297\n",
      "  Number of occurrences of 'Cell Phones & Accessories': 246\n",
      "  Number of occurrences of 'All Electronics': 188\n",
      "  Number of occurrences of 'Premium Beauty': 159\n",
      "  Number of occurrences of 'Grocery': 158\n",
      "  Number of occurrences of 'Baby': 154\n",
      "  Number of occurrences of 'Computers': 117\n",
      "  Number of occurrences of 'Camera & Photo': 65\n",
      "  Number of occurrences of 'Musical Instruments': 46\n",
      "  Number of occurrences of 'Handmade': 20\n",
      "  Number of occurrences of 'Appliances': 19\n",
      "  Number of occurrences of 'Digital Music': 12\n",
      "  Number of occurrences of 'Video Games': 12\n",
      "  Number of occurrences of 'Sports Collectibles': 9\n",
      "  Number of occurrences of 'Home Audio & Theater': 7\n",
      "  Number of occurrences of 'Car Electronics': 6\n",
      "  Number of occurrences of 'Movies & TV': 6\n",
      "  Number of occurrences of 'Books': 4\n",
      "  Number of occurrences of 'Collectibles & Fine Art': 4\n",
      "  Number of occurrences of 'GPS & Navigation': 3\n",
      "  Number of occurrences of 'Portable Audio & Accessories': 2\n",
      "  Number of occurrences of 'Collectible Coins': 2\n",
      "  Number of occurrences of 'Amazon Devices': 1\n",
      "  Number of occurrences of 'Amazon Fire TV': 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "analyze_ordinal_columns(df, [\"main_category\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From dataset review, we see that the brand and manufacturer were similair columns and wanted to check how many of exact matches are there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lower = df.astype(str).apply(lambda x: x.str.lower())\n",
    "total_rows = len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_store_match = (df_lower[\"brand\"] == df_lower[\"store\"]).sum() / total_rows * 100\n",
    "brand_manufacturer_match = (df_lower[\"brand\"] == df_lower[\"manufacturer\"]).sum() / total_rows * 100\n",
    "store_manufacturer_match = (df_lower[\"store\"] == df_lower[\"manufacturer\"]).sum() / total_rows * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brand & Store match: 61.35%\n",
      "Brand & Manufacturer match: 89.89%\n",
      "Store & Manufacturer match: 51.76%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Brand & Store match: {brand_store_match:.2f}%\")\n",
    "print(f\"Brand & Manufacturer match: {brand_manufacturer_match:.2f}%\")\n",
    "print(f\"Store & Manufacturer match: {store_manufacturer_match:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_counts  = df[df[[\"brand\", \"manufacturer\"]].isnull().all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"brand\"] = df[\"brand\"].fillna(df[\"store\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping unused columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"store\", \"manufacturer\", \"price\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding images and embellished description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_ds = load_dataset(\"smartcat/Amazon_Sample_Metadata_2023\", name=\"combined_description_formatted\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.DataFrame(temp_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.merge(df, temp_df[['parent_asin', 'images', 'text']], on='parent_asin', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result.rename(columns={'text': 'embellished_description'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result[['parent_asin', 'main_category', 'title',  'description', 'features', 'embellished_description',\n",
    "       'brand', 'images', 'short_query', 'long_query']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the number of categories with low distibution so they can be saved in a list and later in the test split of the dataset so the accuracy of the model could be tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "  Number of occurrences of 'AMAZON FASHION': 168513\n",
      "  Number of occurrences of 'All Beauty': 36412\n",
      "  Number of occurrences of 'Sports & Outdoors': 22845\n",
      "  Number of occurrences of 'Unknown': 14504\n",
      "  Number of occurrences of 'Health & Personal Care': 5218\n",
      "  Number of occurrences of 'Amazon Home': 3369\n",
      "  Number of occurrences of 'Tools & Home Improvement': 1882\n",
      "  Number of occurrences of 'Automotive': 972\n",
      "  Number of occurrences of 'Industrial & Scientific': 644\n",
      "  Number of occurrences of 'Office Products': 482\n",
      "  Number of occurrences of 'Arts, Crafts & Sewing': 336\n",
      "  Number of occurrences of 'Pet Supplies': 332\n",
      "  Number of occurrences of 'Toys & Games': 297\n",
      "  Number of occurrences of 'Cell Phones & Accessories': 246\n",
      "  Number of occurrences of 'All Electronics': 188\n",
      "  Number of occurrences of 'Premium Beauty': 159\n",
      "  Number of occurrences of 'Grocery': 158\n",
      "  Number of occurrences of 'Baby': 154\n",
      "  Number of occurrences of 'Computers': 117\n",
      "  Number of occurrences of 'Camera & Photo': 65\n",
      "  Number of occurrences of 'Musical Instruments': 46\n",
      "  Number of occurrences of 'Handmade': 20\n",
      "  Number of occurrences of 'Appliances': 19\n",
      "  Number of occurrences of 'Digital Music': 12\n",
      "  Number of occurrences of 'Video Games': 12\n",
      "  Number of occurrences of 'Sports Collectibles': 9\n",
      "  Number of occurrences of 'Home Audio & Theater': 7\n",
      "  Number of occurrences of 'Car Electronics': 6\n",
      "  Number of occurrences of 'Movies & TV': 6\n",
      "  Number of occurrences of 'Books': 4\n",
      "  Number of occurrences of 'Collectibles & Fine Art': 4\n",
      "  Number of occurrences of 'GPS & Navigation': 3\n",
      "  Number of occurrences of 'Portable Audio & Accessories': 2\n",
      "  Number of occurrences of 'Collectible Coins': 2\n",
      "  Number of occurrences of 'Amazon Devices': 1\n",
      "  Number of occurrences of 'Amazon Fire TV': 1\n",
      "336\n",
      "['Computers', 'Camera & Photo', 'Musical Instruments', 'Handmade', 'Appliances', 'Digital Music', 'Video Games', 'Sports Collectibles', 'Home Audio & Theater', 'Car Electronics', 'Movies & TV', 'Books', 'Collectibles & Fine Art', 'GPS & Navigation', 'Portable Audio & Accessories', 'Collectible Coins', 'Amazon Devices', 'Amazon Fire TV']\n"
     ]
    }
   ],
   "source": [
    "value_counts = df[\"main_category\"].value_counts()\n",
    "print(\"--------------------\")\n",
    "small_count = 0\n",
    "small_counts_list = []\n",
    "for value, count in value_counts.items():\n",
    "    print(f\"  Number of occurrences of '{value}': {count}\")\n",
    "    if count < 150:\n",
    "        small_count += count\n",
    "        small_counts_list.append(value)\n",
    "print(small_count)\n",
    "print(small_counts_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13071539446093516 %\n"
     ]
    }
   ],
   "source": [
    "# Percentage of category counts under 150\n",
    "print(small_count * 100 /len(df),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small_counts = df[df[\"main_category\"].isin(small_counts_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small_counts = df_small_counts.sample(frac=1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_without_small = df[~df[\"parent_asin\"].isin(df_small_counts[\"parent_asin\"].to_list())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_without_small = df_without_small.sample(frac=1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making the train, validation and test split using the 80-10-10 split where, 80% of the dataset will be taken for the train, 10% of dataset for the validation and the last 10% (including the small distibution categories) will be taken for the test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205637 25704 25706\n"
     ]
    }
   ],
   "source": [
    "# Compute exact train, validation, and test sizes\n",
    "total_rows = len(df)\n",
    "train_len = int(total_rows * 0.8)  # 80% of total rows\n",
    "validation_len = int(total_rows * 0.1)  # 10% of total rows\n",
    "\n",
    "# Ensure all rows are allocated by assigning remaining rows to test\n",
    "test_len = total_rows - (train_len + validation_len + small_count)  # Remaining rows go to test\n",
    "\n",
    "print(train_len, validation_len, test_len + small_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df_without_small[:train_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_df = df_without_small[train_len:train_len + validation_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = df_without_small[(train_len + validation_len):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.concat([test_df, df_small_counts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.reset_index(drop=True)\n",
    "validation_df = validation_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting data and splits (train, validation, test) into Dataset from pandas and making one final dataset with those 3 splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "validation_dataset = Dataset.from_pandas(validation_df)\n",
    "test_dataset = Dataset.from_pandas(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset = DatasetDict({\n",
    "    \"train\": train_dataset,\n",
    "    \"validation\": validation_dataset,\n",
    "    \"test\": test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally dataset is ready for uploading on hugging face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1302ad0cf861441c90068dd297832cc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataset.push_to_hub(\"smartcat/Amazon-2023-GenQ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prod2query",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
