{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading dataset and splitting into train, val and test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, set the column width to be wider so that the DataFrame is displayed more clearly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 500)\n",
    "#pd.reset_option('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then its time to load the datest for preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"smartcat/Amazon_Sample_Metadata_2023\", name=\"product2query_V1\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, set the column 'parent_asin' to be the first in line as its the product index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_column_order = [\"parent_asin\"] + [col for col in df.columns if col != \"parent_asin\"] \n",
    "df = df[new_column_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>main_category</th>\n",
       "      <th>title</th>\n",
       "      <th>features</th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "      <th>store</th>\n",
       "      <th>brand</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>short_query</th>\n",
       "      <th>long_query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B0C1ND3FVR</td>\n",
       "      <td>All Beauty</td>\n",
       "      <td>Murray &amp; Lanman Florida Water Plastic Bottle 7.5 oz</td>\n",
       "      <td>Unisex\\nNot tested on animals</td>\n",
       "      <td>The enduring popularity of world-famous Florida Water is due to its wonderful light floral scent with lemon overtones. Unchanged since 1808, this revitalizing scent is used as an invigorating splash, aftershave, or fragrant addition to the bath. For more than 200 years men and women have loved the Florida Water scent, named for the Fountain of Youth.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Murray &amp; Lanman</td>\n",
       "      <td>Murray &amp; Lanman</td>\n",
       "      <td>Atlas Ethnic</td>\n",
       "      <td>Florida Water Fragrance</td>\n",
       "      <td>Murray &amp; Lanman Florida Water 7.5 oz Plastic Bottle with Classic Floral Scent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B001PIVFU0</td>\n",
       "      <td>All Beauty</td>\n",
       "      <td>GiGi Professional Multi-Purpose Wax Warmer, with See-Through Cover, White</td>\n",
       "      <td>Thermostat-controlled heating</td>\n",
       "      <td>GiGi Professional Multi-Purpose Wax Warmer with See-Through Cover</td>\n",
       "      <td>25.87</td>\n",
       "      <td>GiGi</td>\n",
       "      <td>GiGi</td>\n",
       "      <td>Barg Engine</td>\n",
       "      <td>GiGi Wax Warmer</td>\n",
       "      <td>GiGi Professional Multi-Purpose Wax Warmer with See-Through Cover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B004ZWH3XG</td>\n",
       "      <td>All Beauty</td>\n",
       "      <td>Garnier Fructis Color Sealer, Instant, Lightweight Leave-In, Color Shield, For Color-Treated Hair, 6 oz.</td>\n",
       "      <td>Seals In Color And Conditions For Extra Softness\\nInfused With Acai Berry And Grape Seed Oil\\nFor Color Treated Hair\\nLightweight Formula</td>\n",
       "      <td>Proven to stop dry-out. Fight fade-out. The lightweight formula, infused with acai berry and grape seed oil, instantly seals in color for longer-lasting vibrancy while improving manageability and delivering lasting softness. Uva and uvb protectant help protect hair. Garnier fructis color shield instant color sealer lightweight leave-in instantly seals in color and conditions for extra softness.</td>\n",
       "      <td>24.00</td>\n",
       "      <td>Garnier</td>\n",
       "      <td>Garnier LLC</td>\n",
       "      <td>Garnier LLC</td>\n",
       "      <td>Garnier Fructis Color Sealer</td>\n",
       "      <td>Garnier Fructis Color Shield Instant Color Sealer for Color-Treated Hair</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  parent_asin  ...                                                                     long_query\n",
       "0  B0C1ND3FVR  ...  Murray & Lanman Florida Water 7.5 oz Plastic Bottle with Classic Floral Scent\n",
       "1  B001PIVFU0  ...              GiGi Professional Multi-Purpose Wax Warmer with See-Through Cover\n",
       "2  B004ZWH3XG  ...       Garnier Fructis Color Shield Instant Color Sealer for Color-Treated Hair\n",
       "\n",
       "[3 rows x 11 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some helper functions to check missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_na(df):\n",
    "    \"\"\"_summary_\n",
    "    Prints sum of NA by columns in DataFrame.\n",
    "\n",
    "    Args:\n",
    "       - df (DataFrame): the DataFrame chunk\n",
    "\n",
    "    Prints:\n",
    "       - Number of NA values by column.\n",
    "    \"\"\"\n",
    "    NANs = df.isnull().sum()\n",
    "    print(\"--------------------\")\n",
    "    print(\"Nulls in dataset:\\n\", NANs)\n",
    "\n",
    "def check_empty_lists(df):\n",
    "    \"\"\"\n",
    "    Prints sum of empty lists by columns in DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        - df (DataFrame): the DataFrame chunk\n",
    "\n",
    "    Prints:\n",
    "        - Number of empty lists by column.\n",
    "    \"\"\"\n",
    "    empty_list_counts = df.apply(lambda col: col.apply(lambda x: x == []).sum())\n",
    "    print(\"--------------------\")\n",
    "    print(\"Empty lists:\")\n",
    "\n",
    "    print(empty_list_counts)\n",
    "\n",
    "\n",
    "def check_empty_strings(df):\n",
    "    \"\"\"\n",
    "    Prints sum of empty strings by columns in DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        - df (DataFrame): the DataFrame chunk\n",
    "\n",
    "    Prints:\n",
    "        - Number of empty strings by column.\n",
    "    \"\"\"\n",
    "    empty_strings = (df == \"\").sum()\n",
    "    print(\"--------------------\")\n",
    "    print(\"Empty strings:\")\n",
    "    print(empty_strings[empty_strings > 0])\n",
    "\n",
    "\n",
    "def check_empty_dictionaries(df):\n",
    "    \"\"\"\n",
    "    Prints the count of empty dictionaries by column in the DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "        - df (pd.DataFrame): The DataFrame to check for empty dictionaries.\n",
    "\n",
    "    Prints:\n",
    "        - Number of empty dictionaries by columns.\n",
    "    \"\"\"\n",
    "    # Count the number of empty dictionaries in each column\n",
    "    empty_dicts = df.apply(\n",
    "        lambda x: x.apply(lambda y: isinstance(y, dict) and len(y) == 0).sum()\n",
    "    )\n",
    "\n",
    "    print(\"--------------------\")\n",
    "    print(\"Empty dictionaries:\")\n",
    "    print(empty_dicts[empty_dicts > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Nulls in dataset:\n",
      " parent_asin           0\n",
      "main_category         0\n",
      "title                 0\n",
      "features              0\n",
      "description           0\n",
      "price            143604\n",
      "store                 0\n",
      "brand             62970\n",
      "manufacturer      62970\n",
      "short_query           0\n",
      "long_query            0\n",
      "dtype: int64\n",
      "--------------------\n",
      "Empty lists:\n",
      "parent_asin      0\n",
      "main_category    0\n",
      "title            0\n",
      "features         0\n",
      "description      0\n",
      "price            0\n",
      "store            0\n",
      "brand            0\n",
      "manufacturer     0\n",
      "short_query      0\n",
      "long_query       0\n",
      "dtype: int64\n",
      "--------------------\n",
      "Empty dictionaries:\n",
      "Series([], dtype: int64)\n",
      "--------------------\n",
      "Empty strings:\n",
      "main_category    14537\n",
      "title               22\n",
      "features         10974\n",
      "store              659\n",
      "short_query        482\n",
      "long_query         482\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "check_na(df)\n",
    "check_empty_lists(df)\n",
    "check_empty_dictionaries(df)\n",
    "check_empty_strings(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to to focus on products that have a Title, and every row that doesn't will be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_empty_title = df[df[\"title\"] == '']\n",
    "df_empty_title[\"parent_asin\"]\n",
    "\n",
    "df = df[~df[\"parent_asin\"].isin(df_empty_title[\"parent_asin\"].to_list())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same goes for 'short_query' cause it will be our label for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_short_query = df[df[\"short_query\"] == '']\n",
    "df_short_query[\"parent_asin\"]\n",
    "\n",
    "df = df[~df[\"parent_asin\"].isin(df_short_query[\"parent_asin\"].to_list())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Empty strings:\n",
      "main_category    14504\n",
      "features         10956\n",
      "store              659\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "check_empty_strings(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empty categories are set to 'Unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['main_category'] == '', 'main_category'] = 'Unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Empty strings:\n",
      "features    10956\n",
      "store         659\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "check_empty_strings(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_ordinal_columns(df, process_columns=None, skip_columns=None):\n",
    "    \"\"\"\n",
    "    Analyzes specified columns in the DataFrame for unique values and occurrences.\n",
    "\n",
    "    Parameters:\n",
    "        - df (pd.DataFrame): The DataFrame to analyze.\n",
    "        - process_columns (list): List of column names to process. If None, all columns except skip_columns will be processed.\n",
    "        - skip_columns (list): List of column names to skip.\n",
    "\n",
    "    Prints:\n",
    "        - Number of unique values in each processed column.\n",
    "        - Unique values in each processed column.\n",
    "        - Number of occurrences for each unique value in each processed column.\n",
    "    \"\"\"\n",
    "    if skip_columns is None:\n",
    "        skip_columns = []\n",
    "    if process_columns is None:\n",
    "        process_columns = df.columns.tolist()\n",
    "\n",
    "    # Process the specified columns\n",
    "    for column in process_columns:\n",
    "        if column in skip_columns:\n",
    "            continue  # Skip the column if it is in the skip list\n",
    "        print(\"--------------------\")\n",
    "        print(f\"Analyzing column: '{column}'\")\n",
    "        print(\"--------------------\")\n",
    "        # Number of unique values\n",
    "        num_unique = df[column].nunique()\n",
    "        unique_values = df[column].unique()\n",
    "\n",
    "        print(f\"  Number of unique values: {num_unique}\")\n",
    "        print(\"--------------------\")\n",
    "        print(f\"  Unique values: {unique_values}\")\n",
    "        # Count occurrences of each unique value\n",
    "        value_counts = df[column].value_counts()\n",
    "        print(\"--------------------\")\n",
    "        for value, count in value_counts.items():\n",
    "            print(f\"  Number of occurrences of '{value}': {count}\")\n",
    "\n",
    "        print()  # Newline for readability between columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Analyzing column: 'main_category'\n",
      "--------------------\n",
      "  Number of unique values: 36\n",
      "--------------------\n",
      "  Unique values: ['All Beauty' 'Industrial & Scientific' 'Health & Personal Care' 'Baby'\n",
      " 'AMAZON FASHION' 'Amazon Home' 'Arts, Crafts & Sewing'\n",
      " 'Tools & Home Improvement' 'Unknown' 'Office Products'\n",
      " 'Sports & Outdoors' 'Automotive' 'Grocery' 'All Electronics'\n",
      " 'Car Electronics' 'Camera & Photo' 'Pet Supplies' 'Toys & Games'\n",
      " 'Digital Music' 'Handmade' 'Cell Phones & Accessories' 'Computers'\n",
      " 'Musical Instruments' 'Premium Beauty' 'Appliances' 'Movies & TV'\n",
      " 'Amazon Devices' 'Books' 'Video Games' 'Home Audio & Theater'\n",
      " 'Collectible Coins' 'Portable Audio & Accessories' 'GPS & Navigation'\n",
      " 'Sports Collectibles' 'Collectibles & Fine Art' 'Amazon Fire TV']\n",
      "--------------------\n",
      "  Number of occurrences of 'AMAZON FASHION': 168511\n",
      "  Number of occurrences of 'All Beauty': 36412\n",
      "  Number of occurrences of 'Sports & Outdoors': 22845\n",
      "  Number of occurrences of 'Unknown': 14504\n",
      "  Number of occurrences of 'Health & Personal Care': 5218\n",
      "  Number of occurrences of 'Amazon Home': 3369\n",
      "  Number of occurrences of 'Tools & Home Improvement': 1882\n",
      "  Number of occurrences of 'Automotive': 972\n",
      "  Number of occurrences of 'Industrial & Scientific': 644\n",
      "  Number of occurrences of 'Office Products': 482\n",
      "  Number of occurrences of 'Arts, Crafts & Sewing': 336\n",
      "  Number of occurrences of 'Pet Supplies': 332\n",
      "  Number of occurrences of 'Toys & Games': 297\n",
      "  Number of occurrences of 'Cell Phones & Accessories': 246\n",
      "  Number of occurrences of 'All Electronics': 188\n",
      "  Number of occurrences of 'Premium Beauty': 159\n",
      "  Number of occurrences of 'Grocery': 158\n",
      "  Number of occurrences of 'Baby': 154\n",
      "  Number of occurrences of 'Computers': 117\n",
      "  Number of occurrences of 'Camera & Photo': 65\n",
      "  Number of occurrences of 'Musical Instruments': 46\n",
      "  Number of occurrences of 'Handmade': 20\n",
      "  Number of occurrences of 'Appliances': 19\n",
      "  Number of occurrences of 'Digital Music': 12\n",
      "  Number of occurrences of 'Video Games': 12\n",
      "  Number of occurrences of 'Sports Collectibles': 9\n",
      "  Number of occurrences of 'Home Audio & Theater': 7\n",
      "  Number of occurrences of 'Car Electronics': 6\n",
      "  Number of occurrences of 'Movies & TV': 6\n",
      "  Number of occurrences of 'Books': 4\n",
      "  Number of occurrences of 'Collectibles & Fine Art': 4\n",
      "  Number of occurrences of 'GPS & Navigation': 3\n",
      "  Number of occurrences of 'Portable Audio & Accessories': 2\n",
      "  Number of occurrences of 'Collectible Coins': 2\n",
      "  Number of occurrences of 'Amazon Devices': 1\n",
      "  Number of occurrences of 'Amazon Fire TV': 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "analyze_ordinal_columns(df, [\"main_category\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO:\n",
    "- all categories that have under 150 products should go to test split\n",
    "- check the percentage of matches between store, brand, manufacturer\n",
    "- split the dataset\n",
    "- shuffle the dataset\n",
    "- upload the df to Hugging Face"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prod2query",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
